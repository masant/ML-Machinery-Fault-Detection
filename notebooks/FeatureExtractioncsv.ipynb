{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.fft import fft, fftfreq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile \n",
    "import polars as pl\n",
    "from scipy.stats import entropy, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções\n",
    "\n",
    "Nota: Essas duas funções foram criadas pois fiz a extração de características diretamente no arquivo .zip do dataset. Dá pra fazer isso de uma maneira mais direta e performática, coletando diretamente do arquivo .csv, só fiz por este caminho devido a limitações de espaço em disco. Futuramente pretendo fazer uma versão mais performática deste código, coletando os dados diretamente dos csvs.\n",
    "\n",
    "Note: These two functions were created because I extracted the features directly from the dataset's .zip file. It can be done in a more straightforward and efficient way by retrieving the data directly from the .csv file. I only followed this approach due to disk space limitations. In the future, I intend to create a more optimized version of this code, collecting the data directly from the CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from .zip File\n",
    "\n",
    "Nota: Essas duas funções foram criadas pois fiz a extração de características diretamente no arquivo .zip do dataset. Dá pra fazer isso de uma maneira mais direta e performática, coletando diretamente do arquivo .csv, só fiz por este caminho devido a limitações de espaço em disco. Futuramente pretendo fazer uma versão mais performática deste código, coletando os dados diretamente dos csvs.\n",
    "\n",
    "Note: These two functions were created because I extracted the features directly from the dataset's .zip file. It can be done in a more straightforward and efficient way by retrieving the data directly from the .csv file. I only followed this approach due to disk space limitations. In the future, I intend to create a more optimized version of this code, collecting the data directly from the CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSubFolders(ZipFileName):\n",
    "    zip_file = zipfile.ZipFile(ZipFileName)\n",
    "    folder_list = []\n",
    "    parquet_filename_list = []\n",
    "    #filelist = []\n",
    "    for file in zip_file.infolist():\n",
    "        if file.filename.endswith('.csv'):\n",
    "            file_list = file.filename.split('/')\n",
    "            prefix = '_'.join(file_list[0:len(file_list)-1]).replace('.','_')\n",
    "            folder = '/'.join(file_list[0:len(file_list)-1])\n",
    "            folder_list.append(folder)\n",
    "            folder_list = list(set(folder_list))\n",
    "            folder_list.sort()\n",
    "    return folder_list\n",
    "\n",
    "def ReadCsvFromZipFile(ZipFileName, FolderName, ColumnNames, CastConfig):    \n",
    "    zip_file = zipfile.ZipFile(ZipFileName)\n",
    "    datasets = []\n",
    "    for file in zip_file.infolist():\n",
    "        if file.filename.endswith('.csv') and file.filename.startswith(FolderName):\n",
    "            datasets.append(pl.read_csv(zip_file.open(file.filename), has_header=True, new_columns = ColumnNames).cast(CastConfig))\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacometer Rotating Speed estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TacometerRotatingSpeedEstimate\n",
    "\n",
    "# This function aims to estimate the rotating speed from the tacometer data (Sensor1). \n",
    "\n",
    "def TacometerRotatingSpeedEstimate(fs, N, raw_dataset):\n",
    "# Iterate 4 times\n",
    "    Rf_candidates = []\n",
    "    for i in np.arange(4):\n",
    "        \n",
    "        # Locate the most significant peak |St(k)| and its index (ka)\n",
    "        max_dataset = raw_dataset.select(['index','Sensor1_Magnitude', 'Frequency']).filter(pl.col('index') == np.argmax(raw_dataset['Sensor1_Magnitude']))\n",
    "        ka = max_dataset['index']\n",
    "\n",
    "        #Calculate the frequency estimate\n",
    "        ft = (ka*fs)/(N)\n",
    "\n",
    "        # Save the estimate in the vector \n",
    "        Rf_candidates.append(ft[0])\n",
    "\n",
    "        # Set to zero for (ka-3) <= k <= (ka + 3)\n",
    "        raw_dataset = raw_dataset.with_columns(Sensor1_Magnitude = (pl.when(pl.col('index').is_between(ka[0]-3,ka[0]+3)).then(0).otherwise(pl.col('Sensor1_Magnitude'))))\n",
    "        i = i+1\n",
    "        \n",
    "    return round(min(Rf_candidates), 6) # Return the final rotating-speed estimate\n",
    "\n",
    "def GetMagnitudeHarmonics(Rf, dataset, sensor):\n",
    "    magnitude = dataset.select(['Frequency', sensor]).filter(pl.col('Frequency').is_between(Rf - 0.1, Rf+0.1))\n",
    "    # Get the first 3 harmonics\n",
    "    for i in np.linspace(2,3,2):\n",
    "        filter_data = dataset.select(['Frequency',sensor]).filter(pl.col('Frequency').is_between(i*Rf - 0.1, i*Rf+0.1))\n",
    "        magnitude = pl.concat([magnitude, filter_data], how='vertical')\n",
    "\n",
    "    magnitude = magnitude.rename({sensor: \"HarmonicMagnitude\"})\n",
    "    return magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data to the spectrum space using FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateFFT(SignalData, SamplingRate):\n",
    "\n",
    "\n",
    "    # Parâmetros do sinal\n",
    "    f_s = 50000 # Frequência de amostragem (100 kHz)\n",
    "    signal = np.array(SignalData)     # Sinal de entrada\n",
    "\n",
    "    # Calcular FFT\n",
    "    magnitude = fft(signal)\n",
    "    magnitude = magnitude/len(SignalData)\n",
    "    magnitude = magnitude[:len(SignalData)//2]\n",
    "    frequency = fftfreq(len(signal), 1/f_s)\n",
    "    frequency = frequency[:len(SignalData)//2]\n",
    "    return abs(magnitude), frequency\n",
    "\n",
    "\n",
    "def GetSpectrumData(RawData, SamplingRate):\n",
    "    spectrum_array = []\n",
    "    spectrum = {}\n",
    "    for sensor in RawData.iter_columns():\n",
    "        magnitude, frequency = CalculateFFT(sensor, SamplingRate)\n",
    "        spectrum = pl.DataFrame(\n",
    "            {       \n",
    "                    sensor.name + \"_Magnitude\": magnitude,\n",
    "                    #\"Frequency\": frequency\n",
    "            }\n",
    "        )\n",
    "        spectrum_array.append(spectrum)\n",
    "    frequency = pl.DataFrame(\n",
    "            {\n",
    "                \"Frequency\": frequency\n",
    "            }\n",
    "    )\n",
    "    spectrum_array.append(frequency)\n",
    "    spectrum_data = pl.concat(spectrum_array, how = \"horizontal\")\n",
    "    return spectrum_data\n",
    "\n",
    "def PlotFFTData(spectrum_data):\n",
    "    fig, axs = plt.subplots(8, 1, layout='constrained')\n",
    "    for i, sensor in enumerate(spectrum_data.columns[0:8]):\n",
    "        axs[i].plot(spectrum_data[\"Frequency\"], spectrum_data[sensor])\n",
    "        axs[i].set_title(sensor)\n",
    "\n",
    "\n",
    "    # Hide x labels and tick labels for all but bottom plot.\n",
    "    for ax in axs:\n",
    "        ax.label_outer()\n",
    "\n",
    "# Features array for each dataset\n",
    "#FrequencyFeatures = []\n",
    "# Number of datasets\n",
    "#N_datasets = len(folder_datasets)\n",
    "\n",
    "#Features array for all datasets in the selected folder\n",
    "#FrequencyFeaturesArray = np.zeros((len(folder_datasets),22))\n",
    "\n",
    "def GetFrequencyFeaturesArray(folder_datasets):\n",
    "    N_datasets = len(folder_datasets)\n",
    "    FrequencyFeatures = []\n",
    "    FrequencyFeaturesArray = np.zeros((len(folder_datasets),22))\n",
    "    for i in np.arange(N_datasets):\n",
    "        dataset = folder_datasets[i]\n",
    "        spectrum_data = GetSpectrumData(dataset, SamplingRate).with_row_index(name='index', offset=1) \n",
    "        N = len(spectrum_data['Sensor1_Magnitude'])\n",
    "        Rf = TacometerRotatingSpeedEstimate(SamplingRate, N, spectrum_data)\n",
    "        FrequencyFeatures = [Rf]\n",
    "        for sensor in spectrum_data.columns[2:9]:\n",
    "            magnitudes = np.array(GetMagnitudeHarmonics(Rf, spectrum_data, sensor)['HarmonicMagnitude'])\n",
    "            for magnitude in magnitudes:\n",
    "                FrequencyFeatures.append(magnitude)\n",
    "        FrequencyFeaturesArray[i] = FrequencyFeatures\n",
    "\n",
    "    return FrequencyFeaturesArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ZipFileName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/full.zip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m FolderNames \u001b[38;5;241m=\u001b[39m GetSubFolders(ZipFileName)\n\u001b[0;32m      3\u001b[0m ColumnNames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensor8\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m CastConfig \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mFloat32\n",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m, in \u001b[0;36mGetSubFolders\u001b[1;34m(ZipFileName)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGetSubFolders\u001b[39m(ZipFileName):\n\u001b[1;32m----> 2\u001b[0m     zip_file \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(ZipFileName)\n\u001b[0;32m      3\u001b[0m     folder_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m     parquet_filename_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\math1\\anaconda3\\Lib\\zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ZipFileName = 'dataset/full.zip'\n",
    "FolderNames = GetSubFolders(ZipFileName)\n",
    "ColumnNames = ['Sensor1', 'Sensor2', 'Sensor3', 'Sensor4', 'Sensor5', 'Sensor6', 'Sensor7', 'Sensor8']\n",
    "CastConfig = pl.Float32\n",
    "SamplingRate = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\math1\\AppData\\Local\\Temp\\ipykernel_15220\\633778449.py:21: UserWarning: Polars found a filename. Ensure you pass a path to the file instead of a python file object when possible for best performance.\n",
      "  datasets.append(pl.read_csv(zip_file.open(file.filename), has_header=True, new_columns = ColumnNames).cast(CastConfig))\n"
     ]
    }
   ],
   "source": [
    "# Add Normal datasets\n",
    "normal_datasets = ReadCsvFromZipFile(ZipFileName, 'normal', ColumnNames, CastConfig)\n",
    "normal_frequency_features = GetFrequencyFeaturesArray(normal_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\math1\\AppData\\Local\\Temp\\ipykernel_15220\\633778449.py:21: UserWarning: Polars found a filename. Ensure you pass a path to the file instead of a python file object when possible for best performance.\n",
      "  datasets.append(pl.read_csv(zip_file.open(file.filename), has_header=True, new_columns = ColumnNames).cast(CastConfig))\n"
     ]
    }
   ],
   "source": [
    "# Add Horizontal Datasets\n",
    "horizontal_datasets = ReadCsvFromZipFile(ZipFileName, 'horizontal', ColumnNames, CastConfig)\n",
    "horizontal_frequency_features = GetFrequencyFeaturesArray(horizontal_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\math1\\AppData\\Local\\Temp\\ipykernel_15220\\633778449.py:21: UserWarning: Polars found a filename. Ensure you pass a path to the file instead of a python file object when possible for best performance.\n",
      "  datasets.append(pl.read_csv(zip_file.open(file.filename), has_header=True, new_columns = ColumnNames).cast(CastConfig))\n"
     ]
    }
   ],
   "source": [
    "# Add Vertical Datasets\n",
    "vertical_datasets = ReadCsvFromZipFile(ZipFileName, 'vertical', ColumnNames, CastConfig)\n",
    "vertical_frequency_features =GetFrequencyFeaturesArray(vertical_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\math1\\AppData\\Local\\Temp\\ipykernel_15220\\633778449.py:21: UserWarning: Polars found a filename. Ensure you pass a path to the file instead of a python file object when possible for best performance.\n",
      "  datasets.append(pl.read_csv(zip_file.open(file.filename), has_header=True, new_columns = ColumnNames).cast(CastConfig))\n"
     ]
    }
   ],
   "source": [
    "# Add Imbalance Datasets\n",
    "imbalance_datasets = ReadCsvFromZipFile(ZipFileName, 'imbalance', ColumnNames, CastConfig)\n",
    "imbalance_frequency_features =GetFrequencyFeaturesArray(imbalance_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\math1\\AppData\\Local\\Temp\\ipykernel_15220\\633778449.py:21: UserWarning: Polars found a filename. Ensure you pass a path to the file instead of a python file object when possible for best performance.\n",
      "  datasets.append(pl.read_csv(zip_file.open(file.filename), has_header=True, new_columns = ColumnNames).cast(CastConfig))\n"
     ]
    }
   ],
   "source": [
    "# Add Overhang Datasets\n",
    "overhang_datasets = ReadCsvFromZipFile(ZipFileName, 'overhang', ColumnNames, CastConfig)\n",
    "overhang_frequency_features =GetFrequencyFeaturesArray(overhang_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\math1\\AppData\\Local\\Temp\\ipykernel_15220\\633778449.py:21: UserWarning: Polars found a filename. Ensure you pass a path to the file instead of a python file object when possible for best performance.\n",
      "  datasets.append(pl.read_csv(zip_file.open(file.filename), has_header=True, new_columns = ColumnNames).cast(CastConfig))\n"
     ]
    }
   ],
   "source": [
    "# Add Underhang Datasets\n",
    "underhang_datasets =  ReadCsvFromZipFile(ZipFileName, 'underhang', ColumnNames, CastConfig)\n",
    "underhang_frequency_features =GetFrequencyFeaturesArray(underhang_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1951, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FrequencyFeatures = np.concatenate(\n",
    "    (normal_frequency_features, \n",
    "     horizontal_frequency_features,\n",
    "     vertical_frequency_features,\n",
    "     imbalance_frequency_features,\n",
    "     overhang_frequency_features, \n",
    "     underhang_frequency_features), \n",
    "     axis=0)\n",
    "FrequencyFeatures.shape\n",
    "#np.append(normal_frequency_features, horizontal_frequency_features,vertical_frequency_features,imbalance_frequency_features,overhang_frequency_features, underhang_frequency_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Sensor1</th><th>Sensor2</th><th>Sensor3</th><th>Sensor4</th><th>Sensor5</th><th>Sensor6</th><th>Sensor7</th><th>Sensor8</th></tr><tr><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>4.6038</td><td>-0.051295</td><td>-0.19405</td><td>-0.060071</td><td>-0.41809</td><td>0.036547</td><td>-0.11043</td><td>0.11831</td></tr><tr><td>4.5703</td><td>-0.96908</td><td>0.038033</td><td>-0.028329</td><td>-0.43081</td><td>0.041924</td><td>-0.14331</td><td>-0.071527</td></tr><tr><td>4.587</td><td>0.89127</td><td>0.072973</td><td>0.007453</td><td>-0.40017</td><td>0.04109</td><td>-0.11984</td><td>0.043445</td></tr><tr><td>4.5887</td><td>-1.716</td><td>-0.32929</td><td>-0.033063</td><td>-0.50281</td><td>0.040474</td><td>-0.2527</td><td>0.023901</td></tr><tr><td>4.5675</td><td>1.2403</td><td>0.35401</td><td>0.04046</td><td>-0.36806</td><td>0.044062</td><td>-0.14258</td><td>-0.05488</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌─────────┬───────────┬──────────┬───────────┬──────────┬──────────┬──────────┬───────────┐\n",
       "│ Sensor1 ┆ Sensor2   ┆ Sensor3  ┆ Sensor4   ┆ Sensor5  ┆ Sensor6  ┆ Sensor7  ┆ Sensor8   │\n",
       "│ ---     ┆ ---       ┆ ---      ┆ ---       ┆ ---      ┆ ---      ┆ ---      ┆ ---       │\n",
       "│ f32     ┆ f32       ┆ f32      ┆ f32       ┆ f32      ┆ f32      ┆ f32      ┆ f32       │\n",
       "╞═════════╪═══════════╪══════════╪═══════════╪══════════╪══════════╪══════════╪═══════════╡\n",
       "│ 4.6038  ┆ -0.051295 ┆ -0.19405 ┆ -0.060071 ┆ -0.41809 ┆ 0.036547 ┆ -0.11043 ┆ 0.11831   │\n",
       "│ 4.5703  ┆ -0.96908  ┆ 0.038033 ┆ -0.028329 ┆ -0.43081 ┆ 0.041924 ┆ -0.14331 ┆ -0.071527 │\n",
       "│ 4.587   ┆ 0.89127   ┆ 0.072973 ┆ 0.007453  ┆ -0.40017 ┆ 0.04109  ┆ -0.11984 ┆ 0.043445  │\n",
       "│ 4.5887  ┆ -1.716    ┆ -0.32929 ┆ -0.033063 ┆ -0.50281 ┆ 0.040474 ┆ -0.2527  ┆ 0.023901  │\n",
       "│ 4.5675  ┆ 1.2403    ┆ 0.35401  ┆ 0.04046   ┆ -0.36806 ┆ 0.044062 ┆ -0.14258 ┆ -0.05488  │\n",
       "└─────────┴───────────┴──────────┴───────────┴──────────┴──────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_datasets[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(data):\n",
    "    data = np.array(data)\n",
    "    min_data = np.min(data)\n",
    "    max_data = np.max(data)\n",
    "    data_norm = (data - min_data) / (max_data - min_data)\n",
    "\n",
    "    return data_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateEntropy(data):\n",
    "    raw_hist, raw_bins = np.histogram(data)\n",
    "    hist = raw_hist[raw_hist != 0] \n",
    "    index = np.argwhere(raw_hist == 0)\n",
    "    bins = np.delete(raw_bins, index)\n",
    "    P = hist/hist.sum()\n",
    "    He = -np.sum(P*np.log(P))\n",
    "    return He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTimeFeatures(rawdataset):\n",
    "    TimeFeatures = np.zeros((len(rawdataset), 24))\n",
    "    N_datasets = len(rawdataset)\n",
    "    for i in np.arange(N_datasets):\n",
    "        sensor_features = []\n",
    "        \n",
    "        # Normalization \n",
    "        dataset = Normalization(rawdataset[i])\n",
    "        dataset = pl.DataFrame(dataset, schema=rawdataset[0].columns)\n",
    "        \n",
    "        for sensor in rawdataset[0].columns:\n",
    "            # Entropy\n",
    "            He = pl.DataFrame({\"He_\"+sensor: CalculateEntropy(dataset[sensor])})\n",
    "            #He = dataset.select(pl.col(sensor).entropy(base=2, normalize=False).alias('He_'+ sensor))\n",
    "            #He=\n",
    "\n",
    "            # Mean\n",
    "            Me = dataset.select(pl.mean(sensor).alias('Me_'+ sensor))\n",
    "\n",
    "            # Kurtosis\n",
    "            Ku = dataset.select(pl.col(sensor).kurtosis().alias('Ku_'+ sensor))\n",
    "\n",
    "            sensor_feature = np.concatenate([He, Me, Ku], axis=1)\n",
    "\n",
    "            for feature in sensor_feature[0]:\n",
    "                sensor_features.append(feature)\n",
    "\n",
    "            #Features = pl.concat([He,Me,Ku], how='horizontal')#.to_numpy()\n",
    "        TimeFeatures[i] = sensor_features\n",
    "\n",
    "    return TimeFeatures\n",
    "    #Features = pl.concat(features, how='horizontal')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 24)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Features  - Normal dataset\n",
    "TimeFeatures_normal = GetTimeFeatures(normal_datasets)\n",
    "TimeFeatures_normal.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 24)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Features  - Horizontal dataset\n",
    "TimeFeatures_horizontal = GetTimeFeatures(horizontal_datasets)\n",
    "TimeFeatures_horizontal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Features  - Vertical dataset\n",
    "TimeFeatures_vertical = GetTimeFeatures(vertical_datasets)\n",
    "TimeFeatures_vertical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 24)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Features  - Imbalance dataset\n",
    "TimeFeatures_imbalance = GetTimeFeatures(imbalance_datasets)\n",
    "TimeFeatures_imbalance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Features  - Overhang dataset\n",
    "TimeFeatures_overhang = GetTimeFeatures(overhang_datasets)\n",
    "TimeFeatures_overhang.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 24)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Features  - Underhang dataset\n",
    "TimeFeatures_underhang = GetTimeFeatures(underhang_datasets)\n",
    "TimeFeatures_underhang.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1951, 24)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TimeFeatures = np.concatenate(\n",
    "    (TimeFeatures_normal, \n",
    "     TimeFeatures_horizontal,\n",
    "     TimeFeatures_vertical,\n",
    "     TimeFeatures_imbalance,\n",
    "     TimeFeatures_overhang, \n",
    "     TimeFeatures_underhang), \n",
    "     axis=0)\n",
    "TimeFeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vetor de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1951, 46)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = np.concatenate((FrequencyFeatures,TimeFeatures), axis=1)\n",
    "Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 46)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Rf</th><th>Rf2</th><th>2Rf2</th><th>3Rf2</th><th>Rf3</th><th>2Rf3</th><th>3Rf3</th><th>Rf4</th><th>2Rf4</th><th>3Rf4</th><th>Rf5</th><th>2Rf5</th><th>3Rf5</th><th>Rf6</th><th>2Rf6</th><th>3Rf6</th><th>Rf7</th><th>2Rf7</th><th>3Rf7</th><th>Rf8</th><th>2Rf8</th><th>3Rf8</th><th>He1</th><th>Me1</th><th>Ku1</th><th>He2</th><th>Me2</th><th>Ku2</th><th>He3</th><th>Me3</th><th>Ku3</th><th>He4</th><th>Me4</th><th>Ku4</th><th>He5</th><th>Me5</th><th>Ku5</th><th>He6</th><th>Me6</th><th>Ku6</th><th>He7</th><th>Me7</th><th>Ku7</th><th>He8</th><th>Me8</th><th>Ku8</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>24.000192</td><td>0.000683</td><td>0.000906</td><td>0.001137</td><td>0.002617</td><td>0.001014</td><td>0.000445</td><td>0.0006</td><td>0.000284</td><td>0.000356</td><td>0.042056</td><td>0.005808</td><td>0.002233</td><td>0.00106</td><td>0.0001</td><td>0.000172</td><td>0.011005</td><td>0.002421</td><td>0.001005</td><td>0.00051</td><td>0.001167</td><td>0.000078</td><td>0.898274</td><td>0.381278</td><td>4.304769</td><td>2.018721</td><td>0.380603</td><td>-1.06574</td><td>1.639317</td><td>0.380849</td><td>-0.725947</td><td>1.64874</td><td>0.380965</td><td>-0.377444</td><td>1.878726</td><td>0.384693</td><td>-0.387145</td><td>1.988329</td><td>0.381308</td><td>-0.767456</td><td>1.750532</td><td>0.381528</td><td>-0.250984</td><td>1.724157</td><td>0.381897</td><td>0.065311</td></tr><tr><td>25.600205</td><td>0.002765</td><td>0.002409</td><td>0.002535</td><td>0.004333</td><td>0.000661</td><td>0.000534</td><td>0.000423</td><td>0.000272</td><td>0.000118</td><td>0.05205</td><td>0.009884</td><td>0.009922</td><td>0.001053</td><td>0.000139</td><td>0.000196</td><td>0.013258</td><td>0.001201</td><td>0.00153</td><td>0.000637</td><td>0.001072</td><td>0.000205</td><td>0.928501</td><td>0.467355</td><td>4.168934</td><td>1.962656</td><td>0.468465</td><td>-0.984737</td><td>1.64736</td><td>0.466705</td><td>-0.660431</td><td>1.625401</td><td>0.466797</td><td>-0.307739</td><td>1.919754</td><td>0.468241</td><td>-0.597151</td><td>1.960709</td><td>0.467065</td><td>-0.766667</td><td>1.935416</td><td>0.466715</td><td>-0.583971</td><td>1.661646</td><td>0.467566</td><td>0.241929</td></tr><tr><td>28.000224</td><td>0.000602</td><td>0.000638</td><td>0.000286</td><td>0.001239</td><td>0.000354</td><td>0.001019</td><td>0.000129</td><td>0.000102</td><td>0.000303</td><td>0.010226</td><td>0.000693</td><td>0.005143</td><td>0.000433</td><td>0.000094</td><td>0.000124</td><td>0.002414</td><td>0.000424</td><td>0.000907</td><td>0.000201</td><td>0.000396</td><td>0.000017</td><td>0.971581</td><td>0.466046</td><td>4.138461</td><td>1.997051</td><td>0.471326</td><td>-1.021556</td><td>1.682617</td><td>0.466381</td><td>-0.63432</td><td>1.602516</td><td>0.466484</td><td>-0.226448</td><td>1.854107</td><td>0.462647</td><td>-0.248633</td><td>1.939774</td><td>0.466688</td><td>-0.697357</td><td>1.676124</td><td>0.465161</td><td>-0.018516</td><td>1.685009</td><td>0.468266</td><td>0.063211</td></tr><tr><td>29.600237</td><td>0.002851</td><td>0.001257</td><td>0.001715</td><td>0.007531</td><td>0.002384</td><td>0.000071</td><td>0.00023</td><td>0.000456</td><td>0.00011</td><td>0.05844</td><td>0.007248</td><td>0.005113</td><td>0.001293</td><td>0.002089</td><td>0.000203</td><td>0.015402</td><td>0.002434</td><td>0.000283</td><td>0.000714</td><td>0.001834</td><td>0.000097</td><td>0.943421</td><td>0.469397</td><td>3.967974</td><td>1.981107</td><td>0.472053</td><td>-0.99857</td><td>1.632274</td><td>0.46907</td><td>-0.612934</td><td>1.659394</td><td>0.46918</td><td>-0.207611</td><td>1.921875</td><td>0.465597</td><td>-0.34026</td><td>1.918103</td><td>0.469403</td><td>-0.715218</td><td>1.713411</td><td>0.467762</td><td>0.086913</td><td>1.687376</td><td>0.471156</td><td>0.018236</td></tr><tr><td>31.600253</td><td>0.000253</td><td>0.001906</td><td>0.000774</td><td>0.005902</td><td>0.002845</td><td>0.000786</td><td>0.000117</td><td>0.000404</td><td>0.000176</td><td>0.060609</td><td>0.006867</td><td>0.002695</td><td>0.000802</td><td>0.000042</td><td>0.000153</td><td>0.017627</td><td>0.001733</td><td>0.000928</td><td>0.000655</td><td>0.001507</td><td>0.000029</td><td>0.864854</td><td>0.443574</td><td>3.814004</td><td>1.97154</td><td>0.442476</td><td>-1.000173</td><td>1.679369</td><td>0.44298</td><td>-0.527783</td><td>1.636327</td><td>0.44311</td><td>-0.159738</td><td>1.854548</td><td>0.43891</td><td>-0.203249</td><td>1.984204</td><td>0.443367</td><td>-0.864867</td><td>1.634181</td><td>0.436212</td><td>0.00973</td><td>1.762669</td><td>0.444594</td><td>-0.100906</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 46)\n",
       "┌───────────┬──────────┬──────────┬──────────┬───┬───────────┬──────────┬──────────┬───────────┐\n",
       "│ Rf        ┆ Rf2      ┆ 2Rf2     ┆ 3Rf2     ┆ … ┆ Ku7       ┆ He8      ┆ Me8      ┆ Ku8       │\n",
       "│ ---       ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---       ┆ ---      ┆ ---      ┆ ---       │\n",
       "│ f64       ┆ f64      ┆ f64      ┆ f64      ┆   ┆ f64       ┆ f64      ┆ f64      ┆ f64       │\n",
       "╞═══════════╪══════════╪══════════╪══════════╪═══╪═══════════╪══════════╪══════════╪═══════════╡\n",
       "│ 24.000192 ┆ 0.000683 ┆ 0.000906 ┆ 0.001137 ┆ … ┆ -0.250984 ┆ 1.724157 ┆ 0.381897 ┆ 0.065311  │\n",
       "│ 25.600205 ┆ 0.002765 ┆ 0.002409 ┆ 0.002535 ┆ … ┆ -0.583971 ┆ 1.661646 ┆ 0.467566 ┆ 0.241929  │\n",
       "│ 28.000224 ┆ 0.000602 ┆ 0.000638 ┆ 0.000286 ┆ … ┆ -0.018516 ┆ 1.685009 ┆ 0.468266 ┆ 0.063211  │\n",
       "│ 29.600237 ┆ 0.002851 ┆ 0.001257 ┆ 0.001715 ┆ … ┆ 0.086913  ┆ 1.687376 ┆ 0.471156 ┆ 0.018236  │\n",
       "│ 31.600253 ┆ 0.000253 ┆ 0.001906 ┆ 0.000774 ┆ … ┆ 0.00973   ┆ 1.762669 ┆ 0.444594 ┆ -0.100906 │\n",
       "└───────────┴──────────┴──────────┴──────────┴───┴───────────┴──────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otimizar esse concat no futuro, pra não ter que fazer na mão.\n",
    "FeatureColumns = {'Rf': Features[:,0],\n",
    "'Rf2': Features[:,1],\n",
    "'2Rf2': Features[:,2],\n",
    "'3Rf2': Features[:,3],\n",
    "'Rf3': Features[:,4],\n",
    "'2Rf3': Features[:,5],\n",
    "'3Rf3': Features[:,6],\n",
    "'Rf4': Features[:,7],\n",
    "'2Rf4': Features[:,8],\n",
    "'3Rf4': Features[:,9],\n",
    "'Rf5': Features[:,10],\n",
    "'2Rf5': Features[:,11],\n",
    "'3Rf5': Features[:,12],\n",
    "'Rf6': Features[:,13],\n",
    "'2Rf6': Features[:,14],\n",
    "'3Rf6': Features[:,15],\n",
    "'Rf7': Features[:,16],\n",
    "'2Rf7': Features[:,17],\n",
    "'3Rf7': Features[:,18],\n",
    "'Rf8': Features[:,19],\n",
    "'2Rf8': Features[:,20],\n",
    "'3Rf8': Features[:,21],\n",
    "'He1': Features[:,22],\n",
    "'Me1': Features[:,23],\n",
    "'Ku1': Features[:,24],\n",
    "'He2': Features[:,25],\n",
    "'Me2': Features[:,26],\n",
    "'Ku2': Features[:,27],\n",
    "'He3': Features[:,28],\n",
    "'Me3': Features[:,29],\n",
    "'Ku3': Features[:,30],\n",
    "'He4': Features[:,31],\n",
    "'Me4': Features[:,32],\n",
    "'Ku4': Features[:,33],\n",
    "'He5': Features[:,34],\n",
    "'Me5': Features[:,35],\n",
    "'Ku5': Features[:,36],\n",
    "'He6': Features[:,37],\n",
    "'Me6': Features[:,38],\n",
    "'Ku6': Features[:,39],\n",
    "'He7': Features[:,40],\n",
    "'Me7': Features[:,41],\n",
    "'Ku7': Features[:,42],\n",
    "'He8': Features[:,43],\n",
    "'Me8': Features[:,44],\n",
    "'Ku8': Features[:,45]}\n",
    "\n",
    "FeaturesDataset = pl.DataFrame(FeatureColumns) \n",
    "FeaturesDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1951, 46)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeaturesDataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesDataset.write_csv('dataset/FeaturesDataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
